{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding similar expenses\n",
    " \n",
    "Reading these features:\n",
    "* Name;\n",
    "* Category (can be multiple, if separated with comma);\n",
    "* Cost;\n",
    "* Date (year-month-day);\n",
    "* Weekday;\n",
    "\n",
    "This notebook wishes to find the expenses most similar to another. \n",
    "\n",
    "Additional Parameters:\n",
    "* ignoreEqualNames -> when searching similar expense for an expense of name X, never takes an expense with the same name (even if in a different date). This can be useful for finding similar expenses from a recurrent expense, ignoring all of its previous ;\n",
    "* ignoreAllEqualNames -> when searching similar expenses, if an expense Y was found for expense X, no more expenses with the same name as Y can be compared with X;\n",
    "\n",
    "\n",
    "# Method\n",
    "\n",
    "Currently I will be using cosine_similarity, because its the most simple strategy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\emily\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\emily\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\emily\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\emily\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\emily\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\emily\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0\n",
      "[notice] To update, run: C:\\Users\\Emily\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in c:\\users\\emily\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\emily\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openpyxl) (2.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0\n",
      "[notice] To update, run: C:\\Users\\Emily\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp311-cp311-win_amd64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\emily\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (2.2.2)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.15.1-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "     ---------------------------------------- 0.0/60.8 kB ? eta -:--:--\n",
      "     ------ --------------------------------- 10.2/60.8 kB ? eta -:--:--\n",
      "     ------------ ------------------------- 20.5/60.8 kB 330.3 kB/s eta 0:00:01\n",
      "     ------------------- ------------------ 30.7/60.8 kB 262.6 kB/s eta 0:00:01\n",
      "     ------------------------- ------------ 41.0/60.8 kB 245.8 kB/s eta 0:00:01\n",
      "     -------------------------------------- 60.8/60.8 kB 293.7 kB/s eta 0:00:00\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.6.1-cp311-cp311-win_amd64.whl (11.1 MB)\n",
      "   ---------------------------------------- 0.0/11.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/11.1 MB 1.9 MB/s eta 0:00:06\n",
      "   ---------------------------------------- 0.1/11.1 MB 1.7 MB/s eta 0:00:07\n",
      "   ---------------------------------------- 0.1/11.1 MB 737.3 kB/s eta 0:00:15\n",
      "    --------------------------------------- 0.2/11.1 MB 1.1 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 0.3/11.1 MB 1.5 MB/s eta 0:00:08\n",
      "   - -------------------------------------- 0.3/11.1 MB 1.2 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 0.5/11.1 MB 1.5 MB/s eta 0:00:08\n",
      "   -- ------------------------------------- 0.6/11.1 MB 1.6 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 0.6/11.1 MB 1.5 MB/s eta 0:00:08\n",
      "   -- ------------------------------------- 0.8/11.1 MB 1.8 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 1.1/11.1 MB 2.2 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 1.3/11.1 MB 2.3 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 1.7/11.1 MB 2.9 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 2.3/11.1 MB 3.5 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 2.6/11.1 MB 3.7 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 3.6/11.1 MB 4.9 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 4.6/11.1 MB 6.0 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 5.2/11.1 MB 6.3 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 7.2/11.1 MB 8.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 9.3/11.1 MB 10.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.5/11.1 MB 13.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.1/11.1 MB 19.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.1/11.1 MB 17.2 MB/s eta 0:00:00\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "   ---------------------------------------- 0.0/301.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 301.8/301.8 kB 9.4 MB/s eta 0:00:00\n",
      "Downloading scipy-1.15.1-cp311-cp311-win_amd64.whl (43.9 MB)\n",
      "   ---------------------------------------- 0.0/43.9 MB ? eta -:--:--\n",
      "    --------------------------------------- 1.1/43.9 MB 23.2 MB/s eta 0:00:02\n",
      "   - -------------------------------------- 1.5/43.9 MB 31.6 MB/s eta 0:00:02\n",
      "   - -------------------------------------- 1.5/43.9 MB 31.6 MB/s eta 0:00:02\n",
      "   - -------------------------------------- 1.5/43.9 MB 31.6 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 3.3/43.9 MB 14.0 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 8.6/43.9 MB 28.9 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 9.5/43.9 MB 29.0 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 11.3/43.9 MB 29.7 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 12.0/43.9 MB 54.7 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 12.6/43.9 MB 38.6 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 13.3/43.9 MB 34.4 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 13.5/43.9 MB 34.4 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 13.8/43.9 MB 28.5 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 14.6/43.9 MB 26.2 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 19.2/43.9 MB 27.3 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 23.7/43.9 MB 46.7 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 25.8/43.9 MB 81.8 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 30.4/43.9 MB 81.8 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 35.0/43.9 MB 81.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 37.1/43.9 MB 81.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 41.6/43.9 MB 81.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  43.9/43.9 MB 81.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  43.9/43.9 MB 81.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  43.9/43.9 MB 81.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  43.9/43.9 MB 81.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 43.9/43.9 MB 32.7 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.6.1 scipy-1.15.1 threadpoolctl-3.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0\n",
      "[notice] To update, run: C:\\Users\\Emily\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install openpyxl\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "      <th>cost</th>\n",
       "      <th>date</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Condomínio - fundo reserva</td>\n",
       "      <td>Moradia, Fixas</td>\n",
       "      <td>5.00</td>\n",
       "      <td>2025-02-05</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Air fryer</td>\n",
       "      <td>Moradia, Fixas</td>\n",
       "      <td>200.00</td>\n",
       "      <td>2025-02-05</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Transporte Atacadão ida e volta</td>\n",
       "      <td>Transporte, Uber</td>\n",
       "      <td>19.29</td>\n",
       "      <td>2025-02-03</td>\n",
       "      <td>Monday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Container energetic</td>\n",
       "      <td>Alimentação, Lanche</td>\n",
       "      <td>9.00</td>\n",
       "      <td>2025-02-01</td>\n",
       "      <td>Saturday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RU</td>\n",
       "      <td>Moradia, Fixas</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2025-02-01</td>\n",
       "      <td>Saturday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              name             category    cost       date  \\\n",
       "0       Condomínio - fundo reserva       Moradia, Fixas    5.00 2025-02-05   \n",
       "1                        Air fryer       Moradia, Fixas  200.00 2025-02-05   \n",
       "2  Transporte Atacadão ida e volta     Transporte, Uber   19.29 2025-02-03   \n",
       "3              Container energetic  Alimentação, Lanche    9.00 2025-02-01   \n",
       "4                               RU       Moradia, Fixas    3.00 2025-02-01   \n",
       "\n",
       "     weekday  \n",
       "0  Wednesday  \n",
       "1  Wednesday  \n",
       "2     Monday  \n",
       "3   Saturday  \n",
       "4   Saturday  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "dt = pd.read_excel(\"nlp_example.xlsx\")\n",
    "\n",
    "\n",
    "dt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all categories:  ['Moradia' 'Fixas' 'Transporte' 'Uber' 'Alimentação' 'Lanche' 'Almoço'\n",
      " 'Vestuário' 'Pagamentos']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "      <th>cost</th>\n",
       "      <th>days_since</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Condomínio - fundo reserva</td>\n",
       "      <td>[1, 1, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Air fryer</td>\n",
       "      <td>[1, 1, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>200.00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Transporte Atacadão ida e volta</td>\n",
       "      <td>[0, 0, 1, 1, 0, 0, 0, 0, 0]</td>\n",
       "      <td>19.29</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Container energetic</td>\n",
       "      <td>[0, 0, 0, 0, 1, 1, 0, 0, 0]</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RU</td>\n",
       "      <td>[1, 1, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              name                     category    cost  \\\n",
       "0       Condomínio - fundo reserva  [1, 1, 0, 0, 0, 0, 0, 0, 0]    5.00   \n",
       "1                        Air fryer  [1, 1, 0, 0, 0, 0, 0, 0, 0]  200.00   \n",
       "2  Transporte Atacadão ida e volta  [0, 0, 1, 1, 0, 0, 0, 0, 0]   19.29   \n",
       "3              Container energetic  [0, 0, 0, 0, 1, 1, 0, 0, 0]    9.00   \n",
       "4                               RU  [1, 1, 0, 0, 0, 0, 0, 0, 0]    3.00   \n",
       "\n",
       "   days_since  \n",
       "0           4  \n",
       "1           4  \n",
       "2           2  \n",
       "3           0  \n",
       "4           0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "clean_dt = dt.dropna()\n",
    "\n",
    "# Name wont be used to compare similarity for now\n",
    "clean_dt = clean_dt.drop(columns=[  \"weekday\"])\n",
    "\n",
    "all_categories = clean_dt[\"category\"].apply(lambda x: x.split(\", \")).explode().unique() \n",
    " \n",
    "print(\"all categories: \", all_categories)\n",
    "clean_dt[\"category\"] = clean_dt[\"category\"].apply(lambda x: x.split(\", \"))#.apply(lambda x: (all_categories.tolist().index(i) for i in x))\n",
    "clean_dt[\"category\"] = clean_dt[\"category\"].apply(lambda x: [all_categories.tolist().index(i) for i in x])\n",
    "clean_dt[\"category\"] = clean_dt[\"category\"].apply(lambda x: [1 if i in x else 0 for i in range(len(all_categories))])\n",
    "clean_dt[\"date\"] = pd.to_datetime(clean_dt[\"date\"])\n",
    "\n",
    "# Get the first date as reference\n",
    "reference_date = clean_dt[\"date\"].min()\n",
    "\n",
    "# Compute days since reference date\n",
    "clean_dt[\"days_since\"] = (clean_dt[\"date\"] - reference_date).dt.days\n",
    "clean_dt = clean_dt.drop(columns=[\"date\"])\n",
    "\n",
    "clean_dt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIMILARITIES\n",
      "Condomínio - fundo reserva -> Roupa Pompéi para Anna with 0.91 similarity\n",
      "The average similarity is:  0.7232026976460374\n",
      "Air fryer -> Celular with 1.0 similarity\n",
      "The average similarity is:  0.8944963014255635\n",
      "Transporte Atacadão ida e volta -> Cama with 1.0 similarity\n",
      "The average similarity is:  0.8936884008908769\n",
      "Container energetic -> Container hambúrguer e energético with 1.0 similarity\n",
      "The average similarity is:  0.8860082455771696\n",
      "RU -> Cartão alimentação with 0.92 similarity\n",
      "The average similarity is:  0.8217762816305344\n",
      "RU -> Container energetic with 0.93 similarity\n",
      "The average similarity is:  0.8172300225552594\n",
      "Container hambúrguer e energético -> Aluguel with 1.0 similarity\n",
      "The average similarity is:  0.8923776509493155\n",
      "Rancho -> Aluguel with 1.0 similarity\n",
      "The average similarity is:  0.89312218140776\n",
      "Cama -> Air fryer with 1.0 similarity\n",
      "The average similarity is:  0.8963055240106251\n",
      "Roupa Pompéi para Anna -> Transporte Atacadão ida e volta with 0.98 similarity\n",
      "The average similarity is:  0.8718754744683163\n",
      "Vivo chip -> Celular with 1.0 similarity\n",
      "The average similarity is:  0.8925234693617189\n",
      "Celular -> Air fryer with 1.0 similarity\n",
      "The average similarity is:  0.8939798778034815\n",
      "Aluguel -> Rancho with 1.0 similarity\n",
      "The average similarity is:  0.8931023820495871\n",
      "Cartão alimentação -> Rancho with 1.0 similarity\n",
      "The average similarity is:  0.8937756192945218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Emily\\AppData\\Local\\Temp\\ipykernel_12496\\1129621982.py:33: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  index = int(index)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "rows = clean_dt.shape[0]\n",
    "cosine_sim = []\n",
    "  \n",
    "all_values = [np.array(v).reshape(1, -1)[0][1:] for v in clean_dt.values]\n",
    "\n",
    "all_values = [ np.hstack([x if not isinstance(x, list) else np.array(x) for x in arr]) for arr in all_values]\n",
    "\n",
    "for i in range(rows):\n",
    "    \n",
    "    first_value = clean_dt.iloc[i].values\n",
    "    \n",
    "    first_value = np.array(first_value).reshape(1, -1)[0]\n",
    "    first_value =  np.hstack([x if not isinstance(x, list) else np.array(x) for x in first_value])\n",
    "    similarity = cosine_similarity([first_value[1:]], all_values)\n",
    "    similarity[0][i] = 0\n",
    "    cosine_sim.append(similarity[0])\n",
    "    '''\n",
    "    for j in range(rows):\n",
    "        if i == j:\n",
    "            cosine_sim.append(0)\n",
    "            continue\n",
    "        second_value = clean_dt.iloc[j].values\n",
    "        second_value = np.array(second_value).reshape(1, -1)[0]\n",
    "        cosine_sim.append(cosine_similarity([first_value[1:]], [second_value[1:]])[0][0])\n",
    "    '''\n",
    "\n",
    "print(\"SIMILARITIES\")\n",
    "for i in range(rows):\n",
    "    \n",
    "    highest_similarity = max(cosine_sim[i])\n",
    "    index = np.where(cosine_sim[i] == highest_similarity)[0] \n",
    "    index = int(index)\n",
    "  \n",
    "    print(f\"{clean_dt.iloc[i].values[0]}\", end=\" \")\n",
    "    print(f\"-> {clean_dt.iloc[index].values[0]}\", end=\" \")\n",
    "    print(f\"with {highest_similarity.round(2)} similarity\")\n",
    "    print(\"The average similarity is: \", np.mean(cosine_sim[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Características Derivadas\n",
    "\n",
    "Através das informações iniciais, podemos derivar outras características binárias. A seguir, as possíveis características derivadas:\n",
    "\n",
    "* (✔️) isWeekend -> ;\n",
    "* (✔️) isGlobalExpensive;\n",
    "* (❌)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
